---
title: 隐藏文章
date: 2023-02-10 12:49:51
tags:
  - hide
categories:
  - 隐藏文章
hide: true
---

# 这是一篇隐藏文章

# 云端众包建图算法开发及维护

- 针对高架桥等多层场景，设计并实现激光点云回环质检方法，提高 patch map 建图的成功率
- 针对多 Trip 之间的先验位姿误差较大的问题，实现基于 BnB 的回环检测搜索算法，提高多 Trip 之间回环搜索的成功率
- 对生成的地面 Intensity Map 设计噪点过滤算法，提高地面车道线元素的清晰度
- 负责建图 Pipeline 的维护和优化；开发轨迹质检算法；多线程提高回环检测速度等

# 行车道路场景重建

- 优化 Colmap 中的特征提取和匹配方法，提高 SFM 计算的相机 pose 精度
- Colmap 结合先验点云地图信息，实现对多相机位姿及相机外参的优化，提高位姿精度及路面重建效果
- 基于 RoME 方法实现行车道路路面的 mesh 重建，为下游标注提供新的数据形式
- 尝试基于 2DGS 的物体三维模型生成方法，用于仿真数据生成

# Map Prior 数据生产

- 结合车身的 6 个周视相机和 Intensity Map，推理对应的车道线、路沿等 feature，作为 Map Prior
- 结合非机动车和机动车的车流信息，提高模型对非机动车道和应急车道等特殊车道属性的检测精度
- 实现多 Trip 语义 feature 的对齐模型，自动拼接生成众包的 Map Prior

# 基于 SD link 的全局选路算法

- 实现车端拓扑计算及上报，云端众包更新的数据闭环流程
- 优化静态选路算法：适配拓扑信息；Y 字路口、右转专用道等特殊场景的选路策略优化，减少车辆多余变道、走错路的风险

# 其他

- 有良好的 C++代码编写习惯，具有良好的沟通、协作能力能力，有良好的职业道德和较强的工作责任感。

# 方案

## 3D 资产生成

<p align="center">{% asset_img 2dgs.png %}</p>
- 预处理步骤：
  - sam2分割物体，提取主体
  - Colmap获取pose
  - TODO: 测试must3r
- 重建步骤：
  - 降低背景亮度，提高重建精度

- 后处理：
  - 如何只提取目标物的 mesh？
    - 在对 tsdf 提取 mesh 前，将每一张 depth map 的背景设置为 0。TSDF 融合过程中，深度值为 0 的区域会被视为无效数据，不参与融合。参考：[TSDF Integration](https://www.open3d.org/docs/latest/tutorial/t_reconstruction_system/integration.html)

# 面试准备

## PSNR（峰值信噪比）公式和作用

- PSNR 是一种评价图像质量的指标，用于衡量原始图像和重建图像之间的差异。
- 定义为：给定一个原始图像，另一个图像为重建图像，PSNR 就是原始图像和重建图像之间的均方误差 MSE 的平均值。
- 计算公式为：
  $$
  PSNR = 10 \log_{10} \frac{MAX_{I}^2}{MSE}
  $$
- 其中，MSE 是原始图像和重建图像之间的均方误差，MAX 是图像颜色的最大数值，8 位采样点表示为 255。
  $$
  MSE = \frac{1}{mn} \sum_{i=0}^{m-1} \sum_{j=0}^{n-1} ||I(i, j) - K(i, j)||^2
  $$

## 怎么看待 NeRF 和 3D GS 的差别（关系）？

- NeRF 是一种隐式的表示方法，在几何表面重建效果上要比 3D GS 更好，但是训练效率比较低下。虽然 3D GS 有些 2D GS 表面重建改进工作，但是目前（主流观念里）NeRF 和 SDF 结合的工作仍然在几何上更好。
- 我提到了：NeRF 和 3D GS 共同点：体渲染 alpha blending 公式是大体一样的，后面发展趋势上也是类似的，3DGS 一些改进工作也是沿着 NeRF 的改进思路在发展，比如重光照、反光、（动态 4DGS、抗锯齿、HDR 等等）。
- 面试结束后又想起来了，再补充：3D GS 是一种比较稀疏的显式表示，而且 3DGS 需要 SFM 的点云初始化。NeRF 是一种稠密的场表示，对于 SDS 优化来说，NeRF 更容易优化，生成效果更好。（目前很少有方法直接采用 3D GS 作为生成阶段的 3D 表示，主要是还是优化效果没有 SDF 效果好）

## 正则化的作用和 pytorch 实现

## L1 L2 loss 的区别和优缺点

## 交叉熵 loss，代码

- 交叉熵是信息论中的概念，用来衡量一个概率分布和另一个概率分布之间的距离。
- 在分类问题中，我们通常有一个真实的概率分布（训练数据的分布），以及一个模型生成的概率分布，交叉熵 keyi 衡量这两个分布之间的距离。
- 在模型训练时，通过最小化交叉熵损失函数，可以使模型预测的概率分布逐步接近真实的概率分布。
- 公式:
  $$
  L = -\frac{1}{N} \sum_{i=1}^{N} [y_i \log \hat{y}_i + (1-y_i) \log (1-\hat{y}_i)]
  $$
  ### 交叉熵由来
  - 信息量：
    - 信息论中，信息量的表示方式：
      $$
      I(x_j) = -\ln p(x_j)
      $$
    - 即：概率越小的事件，信息量越大。
  - 熵：
    $$
    H(p) = -\sum_{j}^{n} p(x_j) \ln p(x_j)
    $$
  - 相对熵（KL 散度）：
    - 如果我们对于同一个随机变量$x$有两个单独的概率分布$p(x)$和$q(x)$，可以用 KL 散度衡量这两个分布之间的距离：
      $$
      D_{KL}(p||q) = \sum_{j=1}^n p(x_j) \ln \frac{p(x_j)}{q(x_j)}
      $$
    - n 为事件的所有可能性，D 的值越小，表示 q 分布和 p 分布越接近。
  - 交叉熵：
    - 把上述公式变形：
      $$
      \begin{aligned}
      D_{KL}(p||q) &= \sum_{j=1}^np(x_j)\ln p(x_j) - \sum_{j=1}^np(x_j)\ln q(x_j) \\
      &= H(p, q) - H(p(x))
      \end{aligned}
      $$
    - 其中，$H(p, q)$ 就是两个分布的交叉熵。
- [交叉熵损失函数](https://microsoft.github.io/ai-edu/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/A2-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/%E7%AC%AC1%E6%AD%A5%20-%20%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/03.2-%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/)

## 多 loss 加和，如何实现自适应权重调节

## Neural SDF 学习

## 代码

### 股票最大收益

### 快排

### 青蛙跳

### 平均池化层代码

### Cross-attention 代码和公式

## SSIM Loss 计算

- Structural Similarity (SSIM)，即**结构相似性**。是用来衡量两张图片的质量的一种指标。
- 结构相似度指数从图像组成的角度将结构信息定义为独立于**亮度、对比度**的反映场景中物体结构的属性，并将失真建模为亮度、对比度和结构三个不同因素的组合。
- **用均值作为亮度的估计，标准差作为对比度的估计，协方差作为结构相似程度的度量**。
- 公式：
  $$
  \text{SSIM}(x, y) = \frac{(2\mu_x\mu_y + c_1)(2\sigma_{xy} + c_2)}{(\mu_x^2 + \mu_y^2 + c_1)(\sigma_x^2 + \sigma_y^2 + c_2)}
  $$
- Pytorch 计算 SSIM Loss 的代码：

  ```python
  def ssim(img1, img2, window_size=11, size_average=True):
      channel = img1.size(-3)
      window = create_window(window_size, channel)

      if img1.is_cuda:
          window = window.cuda(img1.get_device())
      window = window.type_as(img1)

      return _ssim(img1, img2, window, window_size, channel, size_average)

  """
  计算两幅图像的结构相似性指数（SSIM）。

  Args:
      img1 (Tensor): 第一幅图像，Tensor类型，形状为[batch_size, channels, height, width]。
      img2 (Tensor): 第二幅图像，Tensor类型，形状为[batch_size, channels, height, width]。
      window (Tensor): 高斯窗函数，Tensor类型，形状为[channels, window_size, window_size]。
      window_size (int): 高斯窗函数的边长。
      channel (int): 图像的通道数。
      size_average (bool, optional): 是否对SSIM值进行平均。默认为True。

  Returns:
      Tensor: SSIM值。如果size_average为True，则返回SSIM的平均值；否则，返回每个图像的SSIM值。
  """
  def _ssim(img1, img2, window, window_size, channel, size_average=True):
    # 卷积计算局部窗口内的均值
    mu1 = F.conv2d(img1, window, padding=window_size // 2, groups=channel)
    mu2 = F.conv2d(img2, window, padding=window_size // 2, groups=channel)

    mu1_sq = mu1.pow(2)
    mu2_sq = mu2.pow(2)
    mu1_mu2 = mu1 * mu2

    # 计算局部窗口内的标准差
    # \sigma_x^2 = E(x^2) - E(x)^2
    sigma1_sq = F.conv2d(img1 * img1, window, padding=window_size // 2, groups=channel) - mu1_sq
    sigma2_sq = F.conv2d(img2 * img2, window, padding=window_size // 2, groups=channel) - mu2_sq
    sigma12 = F.conv2d(img1 * img2, window, padding=window_size // 2, groups=channel) - mu1_mu2

    C1 = 0.01 ** 2
    C2 = 0.03 ** 2

    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))

    if size_average:
        return ssim_map.mean()
    else:
        return ssim_map.mean(1).mean(1).mean(1)
  ```
